{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM,Dropout,Flatten,BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:\\\\Users\\\\sanja\\\\PycharmProjects\\\\Music_Genre\\\\data_10.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "  \n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    print(\"Data succesfully loaded!\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data succesfully loaded!\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\n",
    "X_train,X_validation,y_train,y_validation = train_test_split(X_train,y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64,input_shape=input_shape,return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "              \n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(Adam(lr = 0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanja\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\sanja\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 130, 64)           19968     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 57,802\n",
      "Trainable params: 57,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5991 samples, validate on 1498 samples\n",
      "Epoch 1/50\n",
      "5991/5991 [==============================] - 49s 8ms/sample - loss: 2.2410 - acc: 0.1784 - val_loss: 2.1243 - val_acc: 0.2997\n",
      "Epoch 2/50\n",
      "5991/5991 [==============================] - 49s 8ms/sample - loss: 1.9895 - acc: 0.3203 - val_loss: 1.8285 - val_acc: 0.3672\n",
      "Epoch 3/50\n",
      "5991/5991 [==============================] - 58s 10ms/sample - loss: 1.8028 - acc: 0.3632 - val_loss: 1.7113 - val_acc: 0.3872\n",
      "Epoch 4/50\n",
      "5991/5991 [==============================] - 51s 9ms/sample - loss: 1.6967 - acc: 0.3929 - val_loss: 1.6356 - val_acc: 0.4139\n",
      "Epoch 5/50\n",
      "5991/5991 [==============================] - 52s 9ms/sample - loss: 1.6231 - acc: 0.4248 - val_loss: 1.5675 - val_acc: 0.4486\n",
      "Epoch 6/50\n",
      "5991/5991 [==============================] - 51s 9ms/sample - loss: 1.5551 - acc: 0.4508 - val_loss: 1.5158 - val_acc: 0.4626\n",
      "Epoch 7/50\n",
      "5991/5991 [==============================] - 52s 9ms/sample - loss: 1.5072 - acc: 0.4729 - val_loss: 1.4868 - val_acc: 0.4766\n",
      "Epoch 8/50\n",
      "5991/5991 [==============================] - 52s 9ms/sample - loss: 1.4619 - acc: 0.4887 - val_loss: 1.4574 - val_acc: 0.4820\n",
      "Epoch 9/50\n",
      "5991/5991 [==============================] - 52s 9ms/sample - loss: 1.4104 - acc: 0.5064 - val_loss: 1.4274 - val_acc: 0.4853\n",
      "Epoch 10/50\n",
      "5991/5991 [==============================] - 53s 9ms/sample - loss: 1.3771 - acc: 0.5213 - val_loss: 1.4085 - val_acc: 0.4920\n",
      "Epoch 11/50\n",
      "5991/5991 [==============================] - 52s 9ms/sample - loss: 1.3508 - acc: 0.5219 - val_loss: 1.3842 - val_acc: 0.5080\n",
      "Epoch 12/50\n",
      "5991/5991 [==============================] - 52s 9ms/sample - loss: 1.3238 - acc: 0.5378 - val_loss: 1.3515 - val_acc: 0.5120\n",
      "Epoch 13/50\n",
      "5991/5991 [==============================] - 51s 9ms/sample - loss: 1.2997 - acc: 0.5470 - val_loss: 1.3482 - val_acc: 0.5227\n",
      "Epoch 14/50\n",
      "5991/5991 [==============================] - 53s 9ms/sample - loss: 1.2603 - acc: 0.5597 - val_loss: 1.3172 - val_acc: 0.5287\n",
      "Epoch 15/50\n",
      "5991/5991 [==============================] - 53s 9ms/sample - loss: 1.2465 - acc: 0.5754 - val_loss: 1.3075 - val_acc: 0.5300\n",
      "Epoch 16/50\n",
      "5991/5991 [==============================] - 53s 9ms/sample - loss: 1.2317 - acc: 0.5750 - val_loss: 1.2943 - val_acc: 0.5401\n",
      "Epoch 17/50\n",
      "5991/5991 [==============================] - 52s 9ms/sample - loss: 1.2235 - acc: 0.5754 - val_loss: 1.3055 - val_acc: 0.5360\n",
      "Epoch 18/50\n",
      "5991/5991 [==============================] - 52s 9ms/sample - loss: 1.1958 - acc: 0.5907 - val_loss: 1.2803 - val_acc: 0.5501\n",
      "Epoch 19/50\n",
      "5991/5991 [==============================] - 54s 9ms/sample - loss: 1.1962 - acc: 0.5849 - val_loss: 1.2947 - val_acc: 0.5347\n",
      "Epoch 20/50\n",
      "5991/5991 [==============================] - 53s 9ms/sample - loss: 1.1668 - acc: 0.6016 - val_loss: 1.2612 - val_acc: 0.5461\n",
      "Epoch 21/50\n",
      "5991/5991 [==============================] - 55s 9ms/sample - loss: 1.1452 - acc: 0.6024 - val_loss: 1.2616 - val_acc: 0.5447\n",
      "Epoch 22/50\n",
      "5991/5991 [==============================] - 64s 11ms/sample - loss: 1.1254 - acc: 0.6136 - val_loss: 1.2288 - val_acc: 0.5601\n",
      "Epoch 23/50\n",
      "5991/5991 [==============================] - 69s 11ms/sample - loss: 1.1060 - acc: 0.6211 - val_loss: 1.2148 - val_acc: 0.5614\n",
      "Epoch 24/50\n",
      "5991/5991 [==============================] - 54s 9ms/sample - loss: 1.0914 - acc: 0.6308 - val_loss: 1.2307 - val_acc: 0.5581\n",
      "Epoch 25/50\n",
      "5991/5991 [==============================] - 57s 10ms/sample - loss: 1.0791 - acc: 0.6333 - val_loss: 1.2130 - val_acc: 0.5607\n",
      "Epoch 26/50\n",
      "5991/5991 [==============================] - 62s 10ms/sample - loss: 1.0635 - acc: 0.6400 - val_loss: 1.2119 - val_acc: 0.5681\n",
      "Epoch 27/50\n",
      "5991/5991 [==============================] - 69s 11ms/sample - loss: 1.0420 - acc: 0.6468 - val_loss: 1.2033 - val_acc: 0.5674\n",
      "Epoch 28/50\n",
      "5991/5991 [==============================] - 66s 11ms/sample - loss: 1.0358 - acc: 0.6458 - val_loss: 1.2102 - val_acc: 0.5694\n",
      "Epoch 29/50\n",
      "5991/5991 [==============================] - 65s 11ms/sample - loss: 1.0229 - acc: 0.6573 - val_loss: 1.2443 - val_acc: 0.5661\n",
      "Epoch 30/50\n",
      "5991/5991 [==============================] - 67s 11ms/sample - loss: 0.9967 - acc: 0.6643 - val_loss: 1.1764 - val_acc: 0.5714\n",
      "Epoch 31/50\n",
      "5991/5991 [==============================] - 73s 12ms/sample - loss: 0.9850 - acc: 0.6723 - val_loss: 1.1623 - val_acc: 0.5928\n",
      "Epoch 32/50\n",
      "5991/5991 [==============================] - 76s 13ms/sample - loss: 0.9774 - acc: 0.6682 - val_loss: 1.1876 - val_acc: 0.5834\n",
      "Epoch 33/50\n",
      "5991/5991 [==============================] - 70s 12ms/sample - loss: 0.9829 - acc: 0.6708 - val_loss: 1.1807 - val_acc: 0.5848\n",
      "Epoch 34/50\n",
      "5991/5991 [==============================] - 67s 11ms/sample - loss: 0.9707 - acc: 0.6787 - val_loss: 1.1643 - val_acc: 0.5928\n",
      "Epoch 35/50\n",
      "5991/5991 [==============================] - 60s 10ms/sample - loss: 0.9299 - acc: 0.6960 - val_loss: 1.1555 - val_acc: 0.6028\n",
      "Epoch 36/50\n",
      "5991/5991 [==============================] - 63s 11ms/sample - loss: 0.9333 - acc: 0.6920 - val_loss: 1.1540 - val_acc: 0.5935\n",
      "Epoch 37/50\n",
      "5991/5991 [==============================] - 58s 10ms/sample - loss: 0.9299 - acc: 0.6919 - val_loss: 1.1550 - val_acc: 0.6055\n",
      "Epoch 38/50\n",
      "5991/5991 [==============================] - 58s 10ms/sample - loss: 0.9458 - acc: 0.6825 - val_loss: 1.1716 - val_acc: 0.5868\n",
      "Epoch 39/50\n",
      "5991/5991 [==============================] - 62s 10ms/sample - loss: 0.9092 - acc: 0.6980 - val_loss: 1.1269 - val_acc: 0.5988\n",
      "Epoch 40/50\n",
      "5991/5991 [==============================] - 51s 9ms/sample - loss: 0.8964 - acc: 0.6977 - val_loss: 1.1473 - val_acc: 0.6115\n",
      "Epoch 41/50\n",
      "5991/5991 [==============================] - 52s 9ms/sample - loss: 0.8732 - acc: 0.7091 - val_loss: 1.1457 - val_acc: 0.6048\n",
      "Epoch 42/50\n",
      "5991/5991 [==============================] - 62s 10ms/sample - loss: 0.8594 - acc: 0.7102 - val_loss: 1.1320 - val_acc: 0.6148\n",
      "Epoch 43/50\n",
      "5991/5991 [==============================] - 59s 10ms/sample - loss: 0.8722 - acc: 0.7086 - val_loss: 1.1500 - val_acc: 0.6068\n",
      "Epoch 44/50\n",
      "5991/5991 [==============================] - 57s 10ms/sample - loss: 0.8580 - acc: 0.7204 - val_loss: 1.1182 - val_acc: 0.6222\n",
      "Epoch 45/50\n",
      "5991/5991 [==============================] - 56s 9ms/sample - loss: 0.8386 - acc: 0.7219 - val_loss: 1.1164 - val_acc: 0.6195\n",
      "Epoch 46/50\n",
      "5991/5991 [==============================] - 64s 11ms/sample - loss: 0.8361 - acc: 0.7179 - val_loss: 1.1355 - val_acc: 0.5995\n",
      "Epoch 47/50\n",
      "5991/5991 [==============================] - 59s 10ms/sample - loss: 0.8185 - acc: 0.7271 - val_loss: 1.1465 - val_acc: 0.6155\n",
      "Epoch 48/50\n",
      "5991/5991 [==============================] - 62s 10ms/sample - loss: 0.8071 - acc: 0.7296 - val_loss: 1.1204 - val_acc: 0.6142\n",
      "Epoch 49/50\n",
      "5991/5991 [==============================] - 57s 10ms/sample - loss: 0.8637 - acc: 0.7206 - val_loss: 1.1386 - val_acc: 0.6095\n",
      "Epoch 50/50\n",
      "5991/5991 [==============================] - 59s 10ms/sample - loss: 0.8118 - acc: 0.7346 - val_loss: 1.1242 - val_acc: 0.6162\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=35, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_predict = X_test[101]\n",
    "y_to_predict = y_test[101]\n",
    "\n",
    "def predict(model, X, y):\n",
    "\n",
    "    X = X[np.newaxis, ...]  # array shape (1, 130, 13, 1)\n",
    "\n",
    "    # perform prediction\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    # get index with max value\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "\n",
    "    print(\"Target: {}, Predicted label: {}\".format(y, predicted_index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
